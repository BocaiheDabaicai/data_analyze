# 数据分析 - 机器学习

1. 统计学进阶
   
   - 描述统计学，对数据进行描述和总结
   
   - 推断统计学，通过样本做出关于总体的推断或预测
   
   - 假设检验，用来判断数值是否真正的出现了理想的变化
   
   - 样本，总体数据里的一个子集
   
   - 总体的推断结论，由样本数据推测总体数据的结论
   
   - 统计量，描述样本特征的数值
   
   - 参数，描述总体特征的数值
   
   - 独立双样本t检验，两个独立的总体数据里的子集进行样本的平均值检验，判断是否存在统计显著的差异【前提：总体数据大致上呈现正态分布】
     
     - 建立假设，原假设`H0`和备择假设`H1`，即符合条件的假设和不符合条件的假设
     
     - 选择单尾检验或双尾检验
       
       - 单尾检验，即设立原假设（A>B）和备择假设（A<=B）或者相反的情况，进行判断
       
       - 双尾假设，原假设（两个参数不存在差异）、备择假设（两个参数之间存在差异）
     
     - 确定显著水平
       
       - 显著水平低，那么允许检验犯错误的概率低，检验容纳错误的情况少
       
       - 显著水平高，那么允许检验犯错误的概率高，检验容纳错误的情况多
     
     - 计算t值
       
       - $t = \frac {\tilde x1 - \tilde x2} {\sqrt{\frac{s1^2}{n1} + \frac{s2^2}{n2}}}$
       - $\tilde x1$和$\tilde x2$是两个样本的均值
       - $s1^2$和$s2^2$是两个样本的方差
       - $n1$和$n2$是两个样本的大小
     
     - 计算自由度，自由度 = 样本1的数量 + 样本2的数量 - 2
     
     - 获取t值临界值，在网上搜索临界值表，观察计算出来的t值、自由度对应的临界值
     
     - 比较临界值和t值
       
       - t值>=临界值，原假设不成立
       
       - t值<临界值，原假设成立
   
   - 独立双样本z检验
     
     - 建立假设
     
     - 选择单尾检验或双尾检验
     
     - 确定显著水平
     
     - 计算z值
       
       - $z = \frac {\tilde x1 - \tilde x2} {\sqrt{\frac{\sigma 1^2}{n1} + \frac{\sigma 2^2}{n2}}}$
       
       - $\tilde x1$和$\tilde x2$是两个样本的均值
       
       - $\sigma 1^2$和$\sigma 2^2$是两个总体的已知方差
       
       - $n1$和$n2$是两个样本的大小
     
     - 获取z值临界值
     
     - 比较临界值和z值
   
   - 能知道总体的方差，那么就进行独立双样本z检验
   
   - 如果样本的数量>30，那么可以采用独立双样本z检验或者独立双样本t检验
   
   - 如果样本的数量<=30，那么就进行独立双样本t检验
   
   - 提示：独立双样本z检验，可以提供更高的准确性和敏感性

2. 编码过程
   
   - 独立双样本t检验
     
     - 安装依赖包`pip install scipy`
     
     - 引入模块`from scipy.stats import ttest_ind`
     
     - 关键代码：
       
       ```python
       t_stat, p_value = ttest_ind(height_a,height_b)
       alpha = 0.5
       if p_value < alpha:
           print("两组数据有明显差异")
       else:
           print("两组数据无明显差异")
       ```
       
       `ttest_ind(height_a,height_b)`：独立双样本t检验，适合两组样本的数据量较少的情况
       
       `p_value`：此处得到的P值直接与`alpha`值进行比较，即可得到推测结果`alpha`：表示预设的临界值
   
   - 独立双样本z检验
     
     - 安装依赖包`pip install statsmodels`
     
     - 引入模块`from statsmodels.stats.weightstats import ztest`
     
     - 关键代码二：
       
       ```python
       z_stat, p_value = ztest(height_a,height_b,alternative='two-sided')
       ```
       
       `alternative='two-sided'`：表示结果执行双尾检验，只推断两个均值之间是否存在显著差异。设置为`larger`，则表示第一个样本的均值是否显著大于第二个样本的均值；设置为`smaller`，则表示第一个样本的均值是否显著小于第二个样本的均值
       
       `p_value`：此处得到的P值直接与`alpha`值进行比较，即可得到推测结果`alpha`：表示预设的临界值

3. 项目：分析鸢尾花种类数据
   
   - 目的：判断两种鸢尾花的属性数据是否存在显著差异
   
   - 过程：
     
     - 读取数据
     
     - 评估数据
     
     - 清理数据
     
     - 整理数据
     
     - 探索数据【`sns.pairplot`：查看数据的基本情况】
     
     - 分析数据
       
       - 判断使用哪种检验方法【如果样本数量小于30，就使用独立双样本t检验；如果样本数量大于等于30，可以使用独立双样本z检验或独立双样本t检验】
       
       - 引入依赖包
       
       - 按照每种属性的角度，进行逐一分析【萼片的宽度、长度；花瓣的宽度、长度】
         
         - 查看两种样本数据的直方图【`sns.histplot`】
         - 建立建设【原假设：总体数据之间不存在显著差异（H0）；备择假设:总体数据之间存在显著差异。（H1）】（本处的“总体数据”要依据具体对比的属性进行必要的名称切换）
         - 确认检验是单尾还是双尾【我们只检验总体数据之间是否存在明显差异，那么就采用双尾检验；如果涉及到具体的大小判断，那么就采用单尾检验】
         - 确定显著水平【设`alpha`的值】
         - 计算t值和p值
         - 得出结论【表述总体数据之间是否存在显著差异】
       
       - 通过每种属性的显著差异，来判断总体数据之间的显著差异

4. 机器学习
   
   - 简单线性回归，由一个自变量决定一个因变量的变化
     
     - 正相关：自变量增加，而且因变量也增加，那么两种数据之间存在正相关关系
     
     - 负相关：自变量增加，但是因变量减少，那么两种数据之间存在负相关关系
     
     - 相关系数`r`：用来描述两种数据之间的相关程度，取值在-1~1之间，有一个专门计算相关系数的方程式
     
     - 线性回归：使用相关系数预测未知数据的可能走势
     
     - 残差：实际观察值与预测值之间的差值
     
     - 拟合目标：让所有残差的平方和最小
     
     - 最小二乘法：通过拟合目标后，来找到最佳的模型参数，即`b,m`。【相关公式：`y = b+ mx`】
     
     - p值影响：表示自变量对应变量是否有统计显著性影响【p值越大，自变量对应变量越没有影响】
   
   - 多元线性回归，由多个自变量决定一个因变量的变化
     
     - 相关计算公式：`y = b0 + b1x1 + b2x2 + ... + bnxn`，其中`b0`表示截距，`b1,b2,...,bn`表示系数
     
     - 分类变量：它的表示值只有“是”或“否”，一般要引入虚拟变量【1，0】进行表示，假如有N种类型的分类变量，那么我们要引入N-1个虚拟变量进行表示，例如：这是一线城市吗？，是那么填入1，不是那么填入0，并继续询问，这是二线城市吗？以此类别推论下去
     
     - 共线性问题：引入的两个自变量存在强相关关系，一般出现这种情况时，选取其中一个自变量引入即可
     
     - P值影响：如果存在P值比较大的自变量，那么可以将其进行移除，以减少对模型的无关性影响
     
     - $R^2$：衡量线性回归模型整体的预测拟合度
   
   - 线性回归代码应用
     
     - 模块安装`pip install statsmodels`
     
     - 模块引入`import statsmodels.api as sm`
     
     - 特别方法介绍
       
       - `pd.get_dummies(data,columns = ["所在城市"])`：将分类变量`所在城市`拆分为虚拟变量，值的表示形式为`True,False`
       
       - `pd.get_dummies(data,columns = ["所在城市"],dtype=int)`：将分类变量`所在城市`拆分为虚拟变量，值的表示形式为`1,0`
       
       - `pd.get_dummies(data,columns = ["所在城市"],dtype=int,drop_first=True)`：将分类变量`所在城市`拆分为虚拟变量，值的表示形式为`1,0`，并移除第一个虚拟变量，完成N个分类变量用N-1个虚拟变量表示，该方法返回最终结果
     
     - 划分自变量、因变量
       
       - 提取列操作：`data["价格"]、data[["面积","所在城市_B"]]`
       
       - 检查自变量之间的相关性：`某Series.corr() => x["面积"].corr(x["卧室数"])`，绝对值越接近1，说明绝对值越相关
       
       - 检查自变量之间的相关性：`某DataFrame.corr() => x.corr()`，绝对值越接近1，说明绝对值越相关，得到所有表格中所有列与其他列之间的相关性
       
       - 检查自变量之间的相关性：`某DataFrame.corr().abs() => x.corr().abs()`，绝对值越接近1，说明绝对值越相关，得到所有表格中所有列与其他列之间的相关性，值表示为绝对值
       
       - 检查自变量之间的相关性：`sns.heatmap(x.corr().abs(),annot=True),plt.plot()`，绝对值越接近1，说明绝对值越相关，得到所有表格中所有列与其他列之间的相关性，值表示为绝对值，显示结果为热力图，可以更容易观察到结果
       
       - `x = sm.add_contant(x)`：为x表格纳入多元线性方程中的截距值
     
     - 建立线性回归方程
       
       - 建立线性回归方程：`model = sm.OLS(y,x)`
       
       - 建立线性回归方程：`result = sm.OLS(y,x).fit()`，并对数据进行拟合
       
       - 对结果进行展示：`result.summary()`
       
       - 注意关注`coef`一行的数值，它表示线性回归方程中每一项的系数值
       
       - 注意关注`P>[t]`的值，如果超过`0.05`，那么表示该自变量对因变量没有起到很大的作用，要移除掉，并重新进行线性回归
       
       - 注意关注`R-squard`的值，它的值越接近1，就说明模型对因变量的解释程度就越高，即模型拟合度越好
       
       - 预测未知数据，`result.predict()`
       
       - 分类变量处理
         
         - `new_observation['所在城市'] = pd.Categorical(new_observation['所在城市'],categories=['A','B','C','D'])`：设置分类属性`所在城市`的分类值
         
         - `new_observation = pd.get_dummies(new_observation,columns=['所在城市'])`：对分类属性`所在城市`进行分类处理，即扩展表格项
     
     - 项目实战—线性回归预测房价
       
       - 读取数据
       
       - 评估数据
       
       - 清理数据
       
       - 数据可视化探索
       
       - 分析数据
         
         - 引入模块`import statsmodels.api as sm`
         
         - 拷贝数据，避免直接修改原数据
         
         - 对数据进行分类处理，`price = pd.getdummies(price,drop_first=True,columns=['a','b',...,''],dtype=int)`
         
         - 获得因变量，`y = price['price']`
         
         - 整理出其它的自变量，`x = price.drop('price',axis=1)`
         
         - 观察自变量之间的相关性
           
           - 观察值：`x.corr()`
           
           - 设置判断值：`x.corr().abs() > 0.8`
           
           - 观察不同自变量之间是否有相关性过高的情况
         
         - 为自变量添加截距，`x = sm.add_constant(x)`
         
         - 获得回归模型方程的拟合值，`model = sm.OLS(y,x).fit()`
         
         - 显示拟合结果，`model.summary()`，根据拟合结果，移除P值大于0.5的属性，因为这些属性对模型的预测影响度很低
         
         - 移除无关的属性，`x = x.drop(['b','c','d'],axis=1)`，再重新对数据进行拟合
       
       - 预测数据
         
         - 准备预测数据，`predict_data = pd.DataFrame({'a':1,"b":"x"})`
         
         - 对分类数据进行分类定义，`predict_data["a"] = pd.Categorical(predict_data["a"],categories=['yes','no'])`，所有的分类变量都需要转换
         
         - 对分类变量引入虚拟变量，`pd.get_dummies(predict_data,drop_first=True,columns=['a','b','c'],dtype=int)`
         
         - 移除对预测影响不重要的属性
         
         - 预测可能的价格，`value = model.predict(predict_data)`

5. 逻辑回归
   
   - 意义：用于预测事件发生的概率，值的范围在0~1之间
   
   - 预测方法：最大似然估计
   
   - 过程：
     
     - 引入模块`import statsmodels.api as sm`
     
     - 将分类变量转换为虚拟变量`pd.get_dummies(data,columns=["gender","smoking"],dtype=int,drop_first=True)`
     
     - 手动添加系数`x = sm.ad_constant(x)`
     
     - 建立逻辑回归模型，并进行数据拟合`result = sm.Logit(y,x).fit()`
     
     - 查看输出`result.summary()`
     
     - 使用系数计算公式得到结果`np.exp(1.3233)`
     
     - 预测未知数据`result.predict(xxx)`
   
   - 项目—泰坦尼克号幸存者
     
     - 读取数据
     
     - 评估数据
     
     - 清理数据
     
     - 探索数据
     
     - 分析数据，注意：逻辑回归的时候是不允许数据出现空缺值的
       
       - 引入模块
       
       - 用复制好的数据进行分析步骤
       
       - 取出除`Survived`的值以外的属性作为x，并查看x的属性之间的相关性`x.corr()`，移除对模型建立没有显著作用的属性
       
       - 添加截距，`x = sm.add_constant(x)`
       
       - 创建逻辑模型并进行数据拟合，`result = sm.Logit(y,x).fit()`
       
       - 查看拟合结果，`result.summary()`
       
       - 计算自然常数的次方，`np.exp(数字)`
     
     - 预测数据
